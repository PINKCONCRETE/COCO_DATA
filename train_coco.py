#!/usr/bin/env python3
"""
YOLO Model Training on Generated COCO Dataset
==============================================
Train YOLO model on the COCO dataset generated by generate_coco_dataset.py

Author: Generated for YOLO fine-tuning
Date: 2026-01-29
"""

import logging
from pathlib import Path
from dataclasses import dataclass
from typing import Optional

from ultralytics import YOLO

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)


@dataclass
class TrainingConfig:
    """Configuration for YOLO model training."""
    
    # Dataset
    dataset_yaml: Path = Path("coco_dataset/dataset.yaml")
    
    # Model
    model_path: str = "yolo26x.pt"  # Pretrained model
    
    # Training parameters
    epochs: int = 100
    imgsz: int = 640
    batch_size: int = 16
    device: str = "0"  # GPU device, use "cpu" for CPU, "0,1,2,3" for multi-GPU
    
    # Optimization
    optimizer: str = "SGD"  # SGD, Adam, AdamW
    lr0: float = 0.01  # Initial learning rate
    lrf: float = 0.01  # Final learning rate (lr0 * lrf)
    momentum: float = 0.937
    weight_decay: float = 0.0005
    
    # Data augmentation
    hsv_h: float = 0.015  # Hue augmentation
    hsv_s: float = 0.7    # Saturation augmentation
    hsv_v: float = 0.4    # Value augmentation
    degrees: float = 0.0   # Rotation augmentation
    translate: float = 0.1 # Translation augmentation
    scale: float = 0.5     # Scale augmentation
    flipud: float = 0.0    # Vertical flip probability
    fliplr: float = 0.5    # Horizontal flip probability
    mosaic: float = 1.0    # Mosaic augmentation probability
    
    # Training settings
    patience: int = 50     # Early stopping patience
    save_period: int = 10  # Save checkpoint every N epochs
    workers: int = 8       # Number of dataloader workers
    
    # Output
    project: str = "runs/train"
    name: str = "coco_finetune"
    exist_ok: bool = False  # Overwrite existing project/name
    
    # Validation
    val: bool = True
    val_split: float = 0.2  # Validation split if no separate val set
    
    def validate(self):
        """Validate configuration."""
        if not Path(self.dataset_yaml).exists():
            raise ValueError(f"Dataset YAML not found: {self.dataset_yaml}")
        
        if not Path(self.model_path).exists():
            raise ValueError(f"Model file not found: {self.model_path}")
        
        logger.info("Configuration validated successfully")


class YOLOTrainer:
    """YOLO model trainer for COCO dataset."""
    
    def __init__(self, config: TrainingConfig):
        self.config = config
        self.config.validate()
        self.model: Optional[YOLO] = None
    
    def load_model(self):
        """Load pretrained YOLO model."""
        logger.info(f"Loading model: {self.config.model_path}")
        self.model = YOLO(self.config.model_path)
        logger.info(f"Model loaded: {self.model.model_name}")
    
    def train(self):
        """Train the model."""
        if self.model is None:
            self.load_model()
        
        logger.info("=" * 80)
        logger.info("Starting YOLO Training")
        logger.info("=" * 80)
        logger.info(f"Dataset: {self.config.dataset_yaml}")
        logger.info(f"Epochs: {self.config.epochs}")
        logger.info(f"Image size: {self.config.imgsz}")
        logger.info(f"Batch size: {self.config.batch_size}")
        logger.info(f"Device: {self.config.device}")
        logger.info("=" * 80)
        
        # Train the model
        results = self.model.train(
            data=str(self.config.dataset_yaml),
            epochs=self.config.epochs,
            imgsz=self.config.imgsz,
            batch=self.config.batch_size,
            device=self.config.device,
            
            # Optimization
            optimizer=self.config.optimizer,
            lr0=self.config.lr0,
            lrf=self.config.lrf,
            momentum=self.config.momentum,
            weight_decay=self.config.weight_decay,
            
            # Data augmentation
            hsv_h=self.config.hsv_h,
            hsv_s=self.config.hsv_s,
            hsv_v=self.config.hsv_v,
            degrees=self.config.degrees,
            translate=self.config.translate,
            scale=self.config.scale,
            flipud=self.config.flipud,
            fliplr=self.config.fliplr,
            mosaic=self.config.mosaic,
            
            # Training settings
            patience=self.config.patience,
            save_period=self.config.save_period,
            workers=self.config.workers,
            project=self.config.project,
            name=self.config.name,
            exist_ok=self.config.exist_ok,
            val=self.config.val,
            
            # Additional settings
            verbose=True,
            plots=True,
        )
        
        logger.info("=" * 80)
        logger.info("Training Complete!")
        logger.info("=" * 80)
        
        return results
    
    def validate(self):
        """Validate the trained model."""
        if self.model is None:
            logger.error("Model not loaded. Train or load a model first.")
            return None
        
        logger.info("Running validation...")
        metrics = self.model.val()
        
        logger.info("Validation Results:")
        logger.info(f"  mAP50: {metrics.box.map50:.4f}")
        logger.info(f"  mAP50-95: {metrics.box.map:.4f}")
        
        return metrics
    
    def export(self, format: str = "onnx"):
        """Export the trained model."""
        if self.model is None:
            logger.error("Model not loaded. Train or load a model first.")
            return None
        
        logger.info(f"Exporting model to {format}...")
        path = self.model.export(format=format)
        logger.info(f"Model exported to: {path}")
        
        return path
    
    def predict_sample(self, image_path: str, save: bool = True):
        """Run prediction on a sample image."""
        if self.model is None:
            logger.error("Model not loaded. Train or load a model first.")
            return None
        
        logger.info(f"Running prediction on: {image_path}")
        results = self.model(image_path)
        
        if save:
            save_dir = Path(self.config.project) / self.config.name / "predictions"
            save_dir.mkdir(parents=True, exist_ok=True)
            
            for i, result in enumerate(results):
                save_path = save_dir / f"prediction_{i}.jpg"
                result.save(str(save_path))
                logger.info(f"Saved prediction to: {save_path}")
        
        return results


def main():
    """Main training pipeline."""
    # Configure training
    config = TrainingConfig(
        dataset_yaml=Path("coco_dataset/dataset.yaml"),
        model_path="yolo26x.pt",
        epochs=100,
        imgsz=640,
        batch_size=16,
        device="0",  # Change to "cpu" if no GPU available
        workers=8,
        name="coco_finetune",
        exist_ok=False
    )
    
    # Create trainer
    trainer = YOLOTrainer(config)
    
    # Train model
    train_results = trainer.train()
    
    # Validate model
    val_metrics = trainer.validate()
    
    # Export model (optional)
    # trainer.export(format="onnx")
    
    # Test prediction on a sample image (optional)
    # sample_image = "coco_dataset/images/image_00000000.jpg"
    # if Path(sample_image).exists():
    #     trainer.predict_sample(sample_image, save=True)
    
    logger.info("All operations complete!")


if __name__ == "__main__":
    main()
